{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) Implementation\n",
    "\n",
    "This notebook demonstrates a complete implementation of a Convolutional Neural Network for image classification.\n",
    "\n",
    "## Dataset\n",
    "We'll use the MNIST dataset (handwritten digits) for demonstration.\n",
    "\n",
    "## Topics Covered:\n",
    "1. Image Data Preprocessing\n",
    "2. CNN Architecture Design\n",
    "3. Convolutional Layers\n",
    "4. Pooling Layers\n",
    "5. Training and Evaluation\n",
    "6. Visualization of Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "print(f\"\\nNumber of classes: {len(np.unique(y_train))}\")\n",
    "print(f\"Classes: {np.unique(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i].imshow(X_train[i], cmap='gray')\n",
    "    axes[i].set_title(f\"Label: {y_train[i]}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Class distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.xticks(unique)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to include channel dimension\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_encoded = to_categorical(y_train, num_classes=10)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(f\"Training set shape after preprocessing: {X_train.shape}\")\n",
    "print(f\"Training labels shape after encoding: {y_train_encoded.shape}\")\n",
    "print(f\"\\nPixel value range: [{X_train.min()}, {X_train.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# First Convolutional Block\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second Convolutional Block\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Model Compiled Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data augmentation generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Visualize augmented images\n",
    "sample_image = X_train[0].reshape(1, 28, 28, 1)\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(sample_image, batch_size=1):\n",
    "    axes[i].imshow(batch[0].reshape(28, 28), cmap='gray')\n",
    "    axes[i].set_title(f'Augmented {i+1}')\n",
    "    axes[i].axis('off')\n",
    "    i += 1\n",
    "    if i >= 5:\n",
    "        break\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(datagen.flow(X_train, y_train_encoded, batch_size=64),\n",
    "                    validation_data=(X_test, y_test_encoded),\n",
    "                    epochs=30,\n",
    "                    callbacks=[early_stop, reduce_lr],\n",
    "                    verbose=1)\n",
    "\n",
    "print(\"\\nTraining Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display correct and incorrect predictions\n",
    "correct_indices = np.where(y_pred == y_test)[0]\n",
    "incorrect_indices = np.where(y_pred != y_test)[0]\n",
    "\n",
    "# Show some correct predictions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle('Correct Predictions', fontsize=16)\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    idx = correct_indices[i]\n",
    "    axes[i].imshow(X_test[idx].reshape(28, 28), cmap='gray')\n",
    "    axes[i].set_title(f\"Pred: {y_pred[idx]}, True: {y_test[idx]}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show some incorrect predictions\n",
    "if len(incorrect_indices) > 0:\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    fig.suptitle('Incorrect Predictions', fontsize=16)\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(10, len(incorrect_indices))):\n",
    "        idx = incorrect_indices[i]\n",
    "        axes[i].imshow(X_test[idx].reshape(28, 28), cmap='gray')\n",
    "        axes[i].set_title(f\"Pred: {y_pred[idx]}, True: {y_test[idx]}\", color='red')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize Convolutional Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the weights of the first convolutional layer\n",
    "filters, biases = model.layers[0].get_weights()\n",
    "\n",
    "# Normalize filter values to 0-1 for visualization\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "\n",
    "# Plot first 32 filters\n",
    "n_filters = 32\n",
    "fig, axes = plt.subplots(4, 8, figsize=(15, 8))\n",
    "fig.suptitle('First Layer Convolutional Filters', fontsize=16)\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(n_filters):\n",
    "    axes[i].imshow(filters[:, :, 0, i], cmap='gray')\n",
    "    axes[i].set_title(f'Filter {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Visualize Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model to get intermediate layer outputs\n",
    "layer_outputs = [layer.output for layer in model.layers[:6]]  # First 6 layers\n",
    "activation_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "# Get activations for a sample image\n",
    "sample_image = X_test[0].reshape(1, 28, 28, 1)\n",
    "activations = activation_model.predict(sample_image)\n",
    "\n",
    "# Visualize first layer activations\n",
    "first_layer_activation = activations[0]\n",
    "fig, axes = plt.subplots(4, 8, figsize=(15, 8))\n",
    "fig.suptitle('First Layer Feature Maps', fontsize=16)\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(32):\n",
    "    axes[i].imshow(first_layer_activation[0, :, :, i], cmap='viridis')\n",
    "    axes[i].set_title(f'Map {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('cnn_mnist_model.h5')\n",
    "print(\"Model saved as 'cnn_mnist_model.h5'\")\n",
    "\n",
    "# To load the model later:\n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model('cnn_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **CNN Architecture**: Convolutional layers extract spatial features\n",
    "2. **Pooling**: Reduces dimensionality while retaining important features\n",
    "3. **Data Augmentation**: Improves generalization\n",
    "4. **Batch Normalization**: Stabilizes training\n",
    "5. **Dropout**: Prevents overfitting\n",
    "\n",
    "### When to Use CNN:\n",
    "- Image classification\n",
    "- Object detection\n",
    "- Image segmentation\n",
    "- Face recognition\n",
    "- Medical image analysis\n",
    "\n",
    "### Advantages:\n",
    "- Automatically learns spatial hierarchies\n",
    "- Parameter sharing reduces model size\n",
    "- Translation invariant\n",
    "- Excellent for image data\n",
    "\n",
    "### CNN vs ANN:\n",
    "- **CNN**: Best for image/spatial data\n",
    "- **ANN**: Best for tabular/structured data\n",
    "- CNN has fewer parameters due to weight sharing\n",
    "- CNN preserves spatial relationships"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
