{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# üå∏ Iris Flower Classification using K-Nearest Neighbors (KNN)\n",
    "\n",
    "## üìä Project Overview\n",
    "\n",
    "This notebook demonstrates **K-Nearest Neighbors (KNN)** algorithm for multi-class classification on the famous Iris dataset.\n",
    "\n",
    "### üéØ Learning Objectives:\n",
    "- Understand KNN algorithm for classification\n",
    "- Explore different distance metrics\n",
    "- Find optimal K value\n",
    "- Implement complete ML pipeline\n",
    "- Evaluate multi-class classification\n",
    "- Visualize decision boundaries\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î What is K-Nearest Neighbors?\n",
    "\n",
    "**KNN** is a simple, **instance-based** learning algorithm that classifies a data point based on the majority class of its K nearest neighbors.\n",
    "\n",
    "### Key Characteristics:\n",
    "\n",
    "| Aspect | Description |\n",
    "|--------|-------------|\n",
    "| **Type** | Non-parametric, instance-based |\n",
    "| **Learning** | Lazy learning (no training phase) |\n",
    "| **Prediction** | Compare with all training samples |\n",
    "| **Decision** | Majority vote among K neighbors |\n",
    "| **Distance** | Euclidean, Manhattan, Minkowski, etc. |\n",
    "\n",
    "### How It Works:\n",
    "\n",
    "```\n",
    "1. Choose K (number of neighbors)\n",
    "2. Calculate distance from new point to all training points\n",
    "3. Select K nearest neighbors\n",
    "4. Take majority vote\n",
    "5. Assign the most common class\n",
    "```\n",
    "\n",
    "### Visual Example:\n",
    "\n",
    "```\n",
    "Classify \"?\" with K=5:\n",
    "\n",
    "    Setosa (‚óè)      Versicolor (‚ñ†)      Virginica (‚ñ≤)\n",
    "\n",
    "        ‚óè                  ‚ñ†                  ‚ñ≤\n",
    "      ‚óè   ‚óè       ?      ‚ñ†   ‚ñ†            ‚ñ≤   ‚ñ≤\n",
    "        ‚óè                  ‚ñ†                  ‚ñ≤\n",
    "\n",
    "5 Nearest Neighbors: ‚óè ‚óè ‚óè ‚ñ† ‚ñ†\n",
    "Votes: Setosa=3, Versicolor=2\n",
    "‚Üí Prediction: Setosa\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## üìö Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Machine Learning - Dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Machine Learning - Models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Machine Learning - Evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## üìÅ Load Dataset\n",
    "\n",
    "**Dataset**: Iris Flower Dataset (built into scikit-learn)\n",
    "\n",
    "### Dataset Information:\n",
    "- **Source**: UCI Machine Learning Repository (1936, Ronald Fisher)\n",
    "- **Samples**: 150 (50 per class)\n",
    "- **Features**: 4 numerical features\n",
    "- **Classes**: 3 species (Setosa, Versicolor, Virginica)\n",
    "- **Type**: Multi-class classification\n",
    "\n",
    "### Features:\n",
    "1. **sepal_length**: Sepal length in cm\n",
    "2. **sepal_width**: Sepal width in cm\n",
    "3. **petal_length**: Petal length in cm\n",
    "4. **petal_width**: Petal width in cm\n",
    "\n",
    "### Target Classes:\n",
    "- **0**: Setosa\n",
    "- **1**: Versicolor\n",
    "- **2**: Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset from scikit-learn\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract features and target\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Get feature and target names\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Create a DataFrame for easier viewing\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['species'] = pd.Categorical.from_codes(y, target_names)\n",
    "df['species_code'] = y\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of samples: {df.shape[0]}\")\n",
    "print(f\"Number of features: {len(feature_names)}\")\n",
    "print(f\"\\nFeature names: {feature_names}\")\n",
    "print(f\"Target names: {list(target_names)}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## üîç Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Step 1: Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "print(\"üìä Dataset Information:\")\n",
    "print(\"=\"*70)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"üìà Statistical Summary:\")\n",
    "print(\"=\"*70)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîç Missing Values:\")\n",
    "print(\"=\"*70)\n",
    "missing = df.isnull().sum()\n",
    "print(missing if missing.sum() > 0 else \"No missing values found! ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"üîç Duplicate rows: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    print(f\"Removing {duplicates} duplicate rows...\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"‚úÖ New shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Step 2: Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target variable distribution\n",
    "print(\"üéØ Class Distribution:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class_counts = df['species'].value_counts()\n",
    "print(f\"\\nClass Counts:\")\n",
    "print(class_counts)\n",
    "print(f\"\\nPercentage:\")\n",
    "print(df['species'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "sns.countplot(data=df, x='species', ax=axes[0], palette='Set2', order=target_names)\n",
    "axes[0].set_title('Species Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Species', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#90EE90', '#FFB6C1', '#87CEEB']\n",
    "axes[1].pie(class_counts, labels=target_names, autopct='%1.1f%%', \n",
    "            colors=colors, startangle=90)\n",
    "axes[1].set_title('Species Proportion', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Dataset is perfectly balanced!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Step 3: Feature Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of all features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors_hist = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\n",
    "\n",
    "for idx, col in enumerate(feature_names):\n",
    "    axes[idx].hist(df[col], bins=20, edgecolor='black', alpha=0.7, color=colors_hist[idx])\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontweight='bold', fontsize=12)\n",
    "    axes[idx].set_xlabel(col, fontsize=10)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier detection\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(feature_names):\n",
    "    sns.boxplot(y=df[col], ax=axes[idx], color=colors_hist[idx])\n",
    "    axes[idx].set_title(f'Box Plot of {col}', fontweight='bold', fontsize=12)\n",
    "    axes[idx].set_ylabel(col, fontsize=10)\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Step 4: Feature Relationships - Pairwise Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise scatter plots colored by species\n",
    "print(\"üìä Creating pairwise feature relationships...\")\n",
    "sns.pairplot(df, hue='species', markers=['o', 's', 'D'], \n",
    "             palette='Set2', height=2.5, diag_kind='kde')\n",
    "plt.suptitle('Pairwise Feature Relationships by Species', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Observations:\")\n",
    "print(\"- Setosa (green) is clearly separated from others\")\n",
    "print(\"- Versicolor and Virginica have some overlap\")\n",
    "print(\"- Petal measurements are more discriminative than sepal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Step 5: Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[feature_names].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, linewidths=1, square=True, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Correlation Insights:\")\n",
    "print(\"High positive correlations:\")\n",
    "high_corr = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "high_corr = high_corr[high_corr < 1.0]  # Exclude self-correlation\n",
    "print(high_corr[high_corr > 0.8].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Step 6: Feature Analysis by Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plots - Feature comparison by species\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(feature_names):\n",
    "    sns.violinplot(data=df, x='species', y=feature, ax=axes[idx], palette='Set2')\n",
    "    axes[idx].set_title(f'{feature} by Species', fontweight='bold', fontsize=12)\n",
    "    axes[idx].set_xlabel('Species', fontsize=10)\n",
    "    axes[idx].set_ylabel(feature, fontsize=10)\n",
    "    axes[idx].grid(alpha=0.3, axis='y')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary by species\n",
    "print(\"üìä Mean Values by Species:\")\n",
    "print(\"=\"*70)\n",
    "print(df.groupby('species')[feature_names].mean())\n",
    "\n",
    "print(\"\\nüìä Standard Deviation by Species:\")\n",
    "print(\"=\"*70)\n",
    "print(df.groupby('species')[feature_names].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## üîß Data Preprocessing\n",
    "\n",
    "### Step 1: Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df[feature_names].values\n",
    "y = df['species_code'].values\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature names: {feature_names}\")\n",
    "print(f\"Target classes: {target_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Step 2: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (70-30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data split completed!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining target distribution:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f\"  {target_names[cls]}: {cnt}\")\n",
    "print(f\"\\nTesting target distribution:\")\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f\"  {target_names[cls]}: {cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Step 3: Feature Scaling\n",
    "\n",
    "**‚ö†Ô∏è CRITICAL for KNN**: Features must be scaled because KNN uses distance metrics!\n",
    "\n",
    "Without scaling, features with larger ranges will dominate the distance calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for better readability\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "\n",
    "print(\"‚úÖ Feature scaling completed!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nOriginal data (first 5 rows):\")\n",
    "print(pd.DataFrame(X_train[:5], columns=feature_names))\n",
    "print(\"\\nScaled data (first 5 rows):\")\n",
    "print(X_train_scaled_df.head())\n",
    "\n",
    "print(\"\\nüìä Scaling Statistics:\")\n",
    "print(f\"Mean of scaled features: {X_train_scaled.mean(axis=0).round(10)}\")\n",
    "print(f\"Std of scaled features: {X_train_scaled.std(axis=0).round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## ü§ñ Model Training\n",
    "\n",
    "### Model 1: Basic KNN (K=5, Euclidean Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train basic KNN model\n",
    "print(\"ü§ñ Training K-Nearest Neighbors Model...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize KNN with K=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = knn.predict(X_train_scaled)\n",
    "y_test_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Get prediction probabilities\n",
    "y_train_pred_proba = knn.predict_proba(X_train_scaled)\n",
    "y_test_pred_proba = knn.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"‚úÖ Model training completed!\")\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  K (n_neighbors): {knn.n_neighbors}\")\n",
    "print(f\"  Weights: {knn.weights}\")\n",
    "print(f\"  Distance metric: {knn.metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## üìä Model Evaluation\n",
    "\n",
    "### Step 1: Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"üìä ACCURACY SCORES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"Testing Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if train_accuracy - test_accuracy > 0.05:\n",
    "    print(\"‚ö†Ô∏è Possible overfitting detected!\")\n",
    "else:\n",
    "    print(\"‚úÖ Model generalizes well!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Step 2: Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nüìã CLASSIFICATION REPORT - Testing Set:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test, y_test_pred, target_names=target_names))\n",
    "\n",
    "# Per-class metrics\n",
    "precision = precision_score(y_test, y_test_pred, average=None)\n",
    "recall = recall_score(y_test, y_test_pred, average=None)\n",
    "f1 = f1_score(y_test, y_test_pred, average=None)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Species': target_names,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Per-Class Metrics Summary:\")\n",
    "print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Step 3: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.title('Confusion Matrix - K-Nearest Neighbors', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Confusion Matrix Breakdown:\")\n",
    "print(\"=\"*70)\n",
    "for i, species in enumerate(target_names):\n",
    "    print(f\"{species}:\")\n",
    "    print(f\"  Correctly classified: {cm[i, i]}\")\n",
    "    print(f\"  Misclassified: {cm[i].sum() - cm[i, i]}\")\n",
    "    if cm[i].sum() > 0:\n",
    "        print(f\"  Class accuracy: {cm[i, i] / cm[i].sum() * 100:.2f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Step 4: Prediction Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some prediction examples\n",
    "print(\"üîç Sample Predictions:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Select 5 random test samples\n",
    "sample_indices = np.random.choice(len(X_test), 5, replace=False)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    actual = target_names[y_test[idx]]\n",
    "    predicted = target_names[y_test_pred[idx]]\n",
    "    probabilities = y_test_pred_proba[idx]\n",
    "    \n",
    "    print(f\"\\nSample {idx + 1}:\")\n",
    "    print(f\"  Features: {X_test[idx]}\")\n",
    "    print(f\"  Actual: {actual}\")\n",
    "    print(f\"  Predicted: {predicted}\")\n",
    "    print(f\"  Probabilities:\")\n",
    "    for i, species in enumerate(target_names):\n",
    "        print(f\"    {species}: {probabilities[i]:.4f} ({probabilities[i]*100:.2f}%)\")\n",
    "    print(f\"  Correct: {'‚úÖ' if actual == predicted else '‚ùå'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Finding Optimal K Value\n",
    "\n",
    "Let's test different K values to find the optimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different K values\n",
    "print(\"üîç Finding Optimal K Value...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "k_range = range(1, 31)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn_temp = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_temp.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    train_scores.append(knn_temp.score(X_train_scaled, y_train))\n",
    "    test_scores.append(knn_temp.score(X_test_scaled, y_test))\n",
    "\n",
    "# Find optimal K\n",
    "optimal_k = k_range[np.argmax(test_scores)]\n",
    "best_score = max(test_scores)\n",
    "\n",
    "print(f\"\\n‚úÖ Optimal K Value: {optimal_k}\")\n",
    "print(f\"Best Test Accuracy: {best_score:.4f} ({best_score*100:.2f}%)\")\n",
    "\n",
    "# Plot K vs Accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(k_range, train_scores, marker='o', linestyle='-', linewidth=2, \n",
    "         markersize=6, label='Training Accuracy', color='blue')\n",
    "plt.plot(k_range, test_scores, marker='s', linestyle='-', linewidth=2, \n",
    "         markersize=6, label='Testing Accuracy', color='red')\n",
    "plt.axvline(x=optimal_k, color='green', linestyle='--', linewidth=2, \n",
    "            label=f'Optimal K={optimal_k}')\n",
    "plt.xlabel('K Value (Number of Neighbors)', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('K Value vs Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xticks(range(1, 31, 2))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Observations:\")\n",
    "print(f\"- K=1 shows overfitting (training accuracy = {train_scores[0]:.4f})\")\n",
    "print(f\"- Optimal K={optimal_k} balances bias and variance\")\n",
    "print(f\"- Very large K values lead to underfitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## üîÑ Model Variants - Different Distance Metrics\n",
    "\n",
    "### Variant 1: Manhattan Distance (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN with Manhattan distance\n",
    "print(\"ü§ñ Training KNN with Manhattan Distance...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "knn_manhattan = KNeighborsClassifier(n_neighbors=optimal_k, metric='manhattan')\n",
    "knn_manhattan.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_manhattan = knn_manhattan.predict(X_test_scaled)\n",
    "accuracy_manhattan = accuracy_score(y_test, y_pred_manhattan)\n",
    "\n",
    "print(f\"\\nüìä Manhattan Distance Results:\")\n",
    "print(f\"Accuracy: {accuracy_manhattan:.4f} ({accuracy_manhattan*100:.2f}%)\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_manhattan, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Variant 2: Weighted KNN (Distance-Based Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN with distance-based weights\n",
    "print(\"ü§ñ Training KNN with Distance Weights...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "knn_weighted = KNeighborsClassifier(n_neighbors=optimal_k, weights='distance')\n",
    "knn_weighted.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_weighted = knn_weighted.predict(X_test_scaled)\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "\n",
    "print(f\"\\nüìä Weighted KNN Results:\")\n",
    "print(f\"Accuracy: {accuracy_weighted:.4f} ({accuracy_weighted*100:.2f}%)\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_weighted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### Variant 3: Minkowski Distance (p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN with Minkowski distance (p=3)\n",
    "print(\"ü§ñ Training KNN with Minkowski Distance (p=3)...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "knn_minkowski = KNeighborsClassifier(n_neighbors=optimal_k, metric='minkowski', p=3)\n",
    "knn_minkowski.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_minkowski = knn_minkowski.predict(X_test_scaled)\n",
    "accuracy_minkowski = accuracy_score(y_test, y_pred_minkowski)\n",
    "\n",
    "print(f\"\\nüìä Minkowski Distance Results:\")\n",
    "print(f\"Accuracy: {accuracy_minkowski:.4f} ({accuracy_minkowski*100:.2f}%)\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_minkowski, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## üìä Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all model variants\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': [\n",
    "        f'KNN (K={knn.n_neighbors}, Euclidean)',\n",
    "        f'KNN (K={optimal_k}, Euclidean)',\n",
    "        f'KNN (K={optimal_k}, Manhattan)',\n",
    "        f'KNN (K={optimal_k}, Weighted)',\n",
    "        f'KNN (K={optimal_k}, Minkowski p=3)'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        test_accuracy,\n",
    "        best_score,\n",
    "        accuracy_manhattan,\n",
    "        accuracy_weighted,\n",
    "        accuracy_minkowski\n",
    "    ],\n",
    "    'Precision (macro avg)': [\n",
    "        precision_score(y_test, y_test_pred, average='macro'),\n",
    "        precision_score(y_test, knn.predict(X_test_scaled), average='macro'),\n",
    "        precision_score(y_test, y_pred_manhattan, average='macro'),\n",
    "        precision_score(y_test, y_pred_weighted, average='macro'),\n",
    "        precision_score(y_test, y_pred_minkowski, average='macro')\n",
    "    ],\n",
    "    'Recall (macro avg)': [\n",
    "        recall_score(y_test, y_test_pred, average='macro'),\n",
    "        recall_score(y_test, knn.predict(X_test_scaled), average='macro'),\n",
    "        recall_score(y_test, y_pred_manhattan, average='macro'),\n",
    "        recall_score(y_test, y_pred_weighted, average='macro'),\n",
    "        recall_score(y_test, y_pred_minkowski, average='macro')\n",
    "    ],\n",
    "    'F1-Score (macro avg)': [\n",
    "        f1_score(y_test, y_test_pred, average='macro'),\n",
    "        f1_score(y_test, knn.predict(X_test_scaled), average='macro'),\n",
    "        f1_score(y_test, y_pred_manhattan, average='macro'),\n",
    "        f1_score(y_test, y_pred_weighted, average='macro'),\n",
    "        f1_score(y_test, y_pred_minkowski, average='macro')\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nüìä MODEL COMPARISON - All Variants\")\n",
    "print(\"=\"*100)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Find best model\n",
    "best_model_idx = comparison_df['Accuracy'].idxmax()\n",
    "print(f\"\\nüèÜ Best Model: {comparison_df.iloc[best_model_idx]['Model']}\")\n",
    "print(f\"   Accuracy: {comparison_df.iloc[best_model_idx]['Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.2\n",
    "\n",
    "metrics = ['Accuracy', 'Precision (macro avg)', 'Recall (macro avg)', 'F1-Score (macro avg)']\n",
    "colors_bar = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i*width, comparison_df[metric], width, label=metric, color=colors_bar[i], alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Model Variant', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('KNN Model Variants Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(comparison_df['Model'], rotation=45, ha='right', fontsize=9)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "ax.set_ylim([0.9, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## üéì Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "print(\"üîÑ Performing 5-Fold Cross-Validation...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "knn_best = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "cv_scores = cross_val_score(knn_best, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nüìä Cross-Validation Results:\")\n",
    "print(f\"Fold scores: {cv_scores}\")\n",
    "print(f\"Mean accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "print(f\"Min accuracy: {cv_scores.min():.4f}\")\n",
    "print(f\"Max accuracy: {cv_scores.max():.4f}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), cv_scores, marker='o', linestyle='-', linewidth=2, markersize=10, color='#3498db')\n",
    "plt.axhline(y=cv_scores.mean(), color='r', linestyle='--', linewidth=2, \n",
    "            label=f'Mean: {cv_scores.mean():.4f}')\n",
    "plt.fill_between(range(1, 6), cv_scores.mean() - cv_scores.std(), \n",
    "                 cv_scores.mean() + cv_scores.std(), alpha=0.2, color='red')\n",
    "plt.xlabel('Fold', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Cross-Validation Accuracy Scores', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xticks(range(1, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search for best hyperparameters\n",
    "print(\"üîç Performing Grid Search for Hyperparameter Tuning...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\n‚úÖ Grid Search Completed!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_test_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "best_test_accuracy = accuracy_score(y_test, y_test_pred_best)\n",
    "best_precision = precision_score(y_test, y_test_pred_best, average='macro')\n",
    "best_recall = recall_score(y_test, y_test_pred_best, average='macro')\n",
    "best_f1 = f1_score(y_test, y_test_pred_best, average='macro')\n",
    "\n",
    "print(f\"\\nüìä Best Model Performance on Test Set:\")\n",
    "print(f\"Accuracy:  {best_test_accuracy:.4f} ({best_test_accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {best_precision:.4f}\")\n",
    "print(f\"Recall:    {best_recall:.4f}\")\n",
    "print(f\"F1-Score:  {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## üìä Visualizing Decision Boundaries\n",
    "\n",
    "Let's visualize how KNN makes decisions using 2D feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision boundary visualization using 2 features (petal length and petal width)\n",
    "print(\"üé® Creating Decision Boundary Visualization...\")\n",
    "print(\"Using petal length and petal width (most discriminative features)\")\n",
    "\n",
    "# Select two features (indices 2 and 3 are petal length and petal width)\n",
    "X_2d = X[:, [2, 3]]\n",
    "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(\n",
    "    X_2d, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale\n",
    "scaler_2d = StandardScaler()\n",
    "X_train_2d_scaled = scaler_2d.fit_transform(X_train_2d)\n",
    "X_test_2d_scaled = scaler_2d.transform(X_test_2d)\n",
    "\n",
    "# Train KNN on 2D data\n",
    "knn_2d = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn_2d.fit(X_train_2d_scaled, y_train_2d)\n",
    "\n",
    "# Create mesh\n",
    "h = 0.02\n",
    "x_min, x_max = X_train_2d_scaled[:, 0].min() - 1, X_train_2d_scaled[:, 0].max() + 1\n",
    "y_min, y_max = X_train_2d_scaled[:, 1].min() - 1, X_train_2d_scaled[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict on mesh\n",
    "Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ['#FF0000', '#00FF00', '#0000FF']\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.4, cmap=cmap_light)\n",
    "\n",
    "# Plot training points\n",
    "for i, color in enumerate(cmap_bold):\n",
    "    idx = np.where(y_train_2d == i)\n",
    "    plt.scatter(X_train_2d_scaled[idx, 0], X_train_2d_scaled[idx, 1],\n",
    "                c=color, label=target_names[i], edgecolor='black', s=100, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Petal Length (scaled)', fontsize=12)\n",
    "plt.ylabel('Petal Width (scaled)', fontsize=12)\n",
    "plt.title(f'KNN Decision Boundary (K={optimal_k})', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Accuracy on 2D features\n",
    "accuracy_2d = knn_2d.score(X_test_2d_scaled, y_test_2d)\n",
    "print(f\"\\n‚úÖ Accuracy using only 2 features: {accuracy_2d:.4f} ({accuracy_2d*100:.2f}%)\")\n",
    "print(\"üí° Even with just 2 features, KNN achieves high accuracy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## üíæ Model Persistence (Optional)\n",
    "\n",
    "Save the best model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and scaler\n",
    "import pickle\n",
    "\n",
    "# Save best model from GridSearch\n",
    "with open('knn_best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Save scaler\n",
    "with open('knn_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"‚úÖ Model and scaler saved successfully!\")\n",
    "print(\"Files: knn_best_model.pkl, knn_scaler.pkl\")\n",
    "\n",
    "# Example: Load and use model\n",
    "print(\"\\nüìñ Example - How to load and use the saved model:\")\n",
    "print(\"\"\"\n",
    "# Load model\n",
    "with open('knn_best_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Load scaler\n",
    "with open('knn_scaler.pkl', 'rb') as f:\n",
    "    loaded_scaler = pickle.load(f)\n",
    "\n",
    "# Make predictions\n",
    "new_data = [[5.1, 3.5, 1.4, 0.2]]  # Example iris flower\n",
    "new_data_scaled = loaded_scaler.transform(new_data)\n",
    "prediction = loaded_model.predict(new_data_scaled)\n",
    "print(f\"Predicted species: {target_names[prediction[0]]}\")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## üìù Summary and Key Takeaways\n",
    "\n",
    "### üéØ Model Performance:\n",
    "- KNN achieved excellent accuracy on the Iris dataset\n",
    "- Optimal K value was determined through cross-validation\n",
    "- Different distance metrics showed similar performance\n",
    "- Weighted KNN can improve predictions by giving more importance to closer neighbors\n",
    "\n",
    "### üí° Key Learnings:\n",
    "\n",
    "1. **KNN is simple but powerful**\n",
    "   - No training phase (lazy learning)\n",
    "   - Works well for small-medium datasets\n",
    "   - Easy to understand and implement\n",
    "\n",
    "2. **Feature scaling is CRITICAL for KNN**\n",
    "   - Without scaling, features with larger ranges dominate\n",
    "   - StandardScaler transforms all features to similar scales\n",
    "   - ALWAYS scale features before applying KNN\n",
    "\n",
    "3. **Choosing the right K is important**\n",
    "   - K=1: Overfitting, sensitive to noise\n",
    "   - K=large: Underfitting, loses local patterns\n",
    "   - Use cross-validation to find optimal K\n",
    "   - For Iris, optimal K was typically between 3-7\n",
    "\n",
    "4. **Distance metrics matter**\n",
    "   - Euclidean: Most common, works well generally\n",
    "   - Manhattan: Better for high-dimensional data\n",
    "   - Weighted: Closer neighbors get more votes\n",
    "\n",
    "5. **KNN has trade-offs**\n",
    "   - ‚úÖ Pros: Simple, no assumptions, works for non-linear problems\n",
    "   - ‚ùå Cons: Slow prediction, memory-intensive, curse of dimensionality\n",
    "\n",
    "### üîç Iris Dataset Insights:\n",
    "\n",
    "1. **Class Separability**\n",
    "   - Setosa is completely separable from others\n",
    "   - Versicolor and Virginica have slight overlap\n",
    "   - Overall, well-structured data for classification\n",
    "\n",
    "2. **Feature Importance**\n",
    "   - Petal length and petal width are most discriminative\n",
    "   - Sepal measurements are less discriminative\n",
    "   - Even using just 2 features achieves high accuracy\n",
    "\n",
    "3. **Perfect for Learning**\n",
    "   - Clean data (no missing values)\n",
    "   - Balanced classes (50 samples each)\n",
    "   - Small size (150 samples)\n",
    "   - Real-world botanical measurements\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps:\n",
    "\n",
    "1. **Try KNN on other datasets**\n",
    "   - Wine quality dataset\n",
    "   - Breast cancer dataset\n",
    "   - Handwritten digits (MNIST)\n",
    "\n",
    "2. **Compare with other algorithms**\n",
    "   - Logistic Regression\n",
    "   - Support Vector Machines (SVM)\n",
    "   - Decision Trees\n",
    "   - Random Forest\n",
    "   - Neural Networks\n",
    "\n",
    "3. **Explore advanced techniques**\n",
    "   - KD-trees for faster prediction\n",
    "   - Ball-trees for high-dimensional data\n",
    "   - Feature selection\n",
    "   - Dimensionality reduction (PCA)\n",
    "\n",
    "4. **Deploy your model**\n",
    "   - Create a web app with Streamlit or Flask\n",
    "   - Build a REST API\n",
    "   - Deploy to cloud (Heroku, AWS, GCP)\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources:\n",
    "\n",
    "- **Scikit-Learn KNN Documentation**: https://scikit-learn.org/stable/modules/neighbors.html\n",
    "- **StatQuest KNN Video**: https://www.youtube.com/watch?v=HVXime0nQeI\n",
    "- **Understanding Distance Metrics**: https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa\n",
    "- **Curse of Dimensionality**: https://towardsdatascience.com/the-curse-of-dimensionality-50dc6e49aa1e\n",
    "\n",
    "---\n",
    "\n",
    "**‚úÖ Project Complete! You've successfully implemented K-Nearest Neighbors for Iris Classification!**\n",
    "\n",
    "**Happy Learning! üå∏üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
